
"""
Main Agent for ProdigyFlow
-----------------------------------
This agent coordinates:
1. Cleaning Agent
2. Analysis Agent
3. Visualization Agent

It loads the raw dataset, cleans it, analyzes it,
and generates visualizations â€” all in one pipeline.
"""

import json
from pathlib import Path

# Importing your agents
from cleaning_agent import load_data, clean_dataset, save_data, get_cleaning_plan
from analysis_agent import analyze
from visualization_agent import create_visualizations


# ---------------------------------------------------------
# MAIN PIPELINE FUNCTION
# ---------------------------------------------------------
def run_pipeline(
    raw_csv_path="data/data_science_student_marks.csv",
    cleaned_csv_path="data/cleaned_student_data.csv"
):
    print("\nğŸš€ Starting ProdigyFlow Pipeline...\n")

    # -----------------------------------------------------
    # 1. LOAD RAW DATA
    # -----------------------------------------------------
    df = load_data(raw_csv_path)
    if df is None:
        print("âŒ Unable to load dataset. Stopping pipeline.")
        return

    print("\nğŸ“Œ Raw dataset loaded successfully.")
    print(df.head())

    # -----------------------------------------------------
    # 2. GENERATE CLEANING PLAN (Gemini-powered)
    # -----------------------------------------------------
    print("\nğŸ§¹ Generating cleaning plan...")
    plan = get_cleaning_plan(df.head().to_string(), "Automatically clean this dataset.")
    print(f"âœ¨ Cleaning Plan: {plan}")

    # -----------------------------------------------------
    # 3. APPLY CLEANING STEPS
    # -----------------------------------------------------
    print("\nğŸ”§ Applying cleaning steps...")
    cleaned_df = clean_dataset(df, plan)

    # Save cleaned dataset
    save_data(cleaned_df, cleaned_csv_path)
    print(f"ğŸ“ Cleaned dataset saved to: {cleaned_csv_path}")

    # -----------------------------------------------------
    # 4. ANALYSIS AGENT
    # -----------------------------------------------------
    print("\nğŸ“Š Running data analysis...\n")
    insights, metadata = analyze(cleaned_csv_path)

    print("=== INSIGHTS ===")
    print(json.dumps(insights, indent=2))

    print("\n=== METADATA ===")
    print(json.dumps(metadata, indent=2))

    # -----------------------------------------------------
    # 5. VISUALIZATION AGENT
    # -----------------------------------------------------
    print("\nğŸ“ˆ Generating visualizations...\n")
    vis_result = create_visualizations(cleaned_csv_path)

    print("=== VISUALIZATION SUMMARY ===")
    print(json.dumps(vis_result, indent=2))

    print("\nğŸ‰ Pipeline completed successfully!\n")


# ---------------------------------------------------------
# ENTRY POINT
# ---------------------------------------------------------
if __name__ == "__main__":
    run_pipeline()
