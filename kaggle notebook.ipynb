{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ecb4b0",
   "metadata": {},
   "source": [
    "# ProdigyFlow — Kaggle Notebook\n",
    "\n",
    "**Authors:** Komal Harshita, Priyamvadha Sahasvi Nune\n",
    "\n",
    "---\n",
    "\n",
    "## Abstract\n",
    "\n",
    "This notebook presents a structured, academic-style analysis of a student performance dataset used in the ProdigyFlow pipeline. It follows the typical layout: Abstract, Introduction, Dataset Description, Methodology (Cleaning, Analysis, Visualization), Results, Discussion, Conclusion, and References."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d4750",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "Education analytics can reveal insights about student performance, curriculum effectiveness, and potential interventions. In this project, ProdigyFlow automates cleaning, analysis, and visualization tasks using modular agents. This notebook documents the analysis following an academic structure to make the findings clear and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9fc2e",
   "metadata": {},
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "The dataset contains student records with demographic and marks information. Key attributes:\n",
    "\n",
    "- `student_id` — unique identifier\n",
    "- `location` — city\n",
    "- `age` — student age (years)\n",
    "- `sql_marks`, `excel_marks`, `python_marks`, `power_bi_marks`, `english_marks` — subject scores (0-100)\n",
    "\n",
    "**Size:** 500 rows, 8 columns. The data is provided in `data/data_science_student_marks.csv` in this repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb06b1c",
   "metadata": {},
   "source": [
    "## 3. Objectives\n",
    "\n",
    "This notebook aims to:\n",
    "\n",
    "1. Describe the dataset and provide reproducible cleaning steps.\n",
    "2. Perform exploratory data analysis (EDA) and statistical summaries.\n",
    "3. Evaluate correlations and potential relationships between attributes.\n",
    "4. Produce publication-quality visualizations.\n",
    "5. Summarize findings in the style (Results, Discussion, Conclusion)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d488d9",
   "metadata": {},
   "source": [
    "## 4. Setup & Imports\n",
    "\n",
    "Install packages if needed (Kaggle usually has common packages preinstalled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15828ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if running in a fresh environment\n",
    "# !pip install -q pandas numpy matplotlib seaborn scipy statsmodels\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "DATA_PATH = Path('data/data_science_student_marks.csv')\n",
    "REPORTS_DIR = Path('reports')\n",
    "VIS_DIR = Path('visuals')\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VIS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Setup complete. DATA_PATH exists:', DATA_PATH.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085bcba",
   "metadata": {},
   "source": [
    "## 5. Data Loading & Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d361fcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f'Expected data file not found at {DATA_PATH}. Please upload the CSV to this path.')\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Dataset shape:', df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3bc5b",
   "metadata": {},
   "source": [
    "### 5.1 Data Types and Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5cccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77324169",
   "metadata": {},
   "source": [
    "### 5.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a060175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age','sql_marks','excel_marks','python_marks','power_bi_marks','english_marks']\n",
    "\n",
    "df[numeric_cols].describe().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01774b3c",
   "metadata": {},
   "source": [
    "## 6. Methodology — Data Cleaning\n",
    "\n",
    "Describe the cleaning steps and rationale. We apply minimal, reproducible cleaning: remove exact duplicates, ensure numeric columns are numeric, and fill/flag missing values if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning steps (defensive)\n",
    "df_clean = df.copy()\n",
    "# 1. Drop exact duplicates\n",
    "before = df_clean.shape[0]\n",
    "df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
    "after = df_clean.shape[0]\n",
    "print(f'Dropped duplicates: {before - after}')\n",
    "\n",
    "# 2. Ensure numeric types\n",
    "for c in numeric_cols:\n",
    "    df_clean[c] = pd.to_numeric(df_clean[c], errors='coerce')\n",
    "\n",
    "# 3. Report missing values after coercion\n",
    "print('\\nMissing after coercion:')\n",
    "print(df_clean[numeric_cols].isna().sum())\n",
    "\n",
    "# 4. If any numeric missing, fill with column median (deterministic, reproducible)\n",
    "for c in numeric_cols:\n",
    "    if df_clean[c].isna().sum() > 0:\n",
    "        med = df_clean[c].median()\n",
    "        df_clean[c].fillna(med, inplace=True)\n",
    "\n",
    "print('\\nMissing now:')\n",
    "print(df_clean.isna().sum())\n",
    "\n",
    "# Save cleaned copy\n",
    "cleaned_path = Path('data/cleaned_student_data_academic.csv')\n",
    "df_clean.to_csv(cleaned_path, index=False)\n",
    "print('\\nSaved cleaned dataset to', cleaned_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff70f9",
   "metadata": {},
   "source": [
    "## 7. Results — Exploratory Data Analysis\n",
    "\n",
    "### 7.1 Distributions of Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    sns.histplot(df_clean[col], kde=True)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_DIR / 'distributions_grid.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bfbd11",
   "metadata": {},
   "source": [
    "### 7.2 Boxplots (Detect outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(data=df_clean[numeric_cols])\n",
    "plt.title('Boxplot of numeric columns')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_DIR / 'boxplots.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39d9a05",
   "metadata": {},
   "source": [
    "### 7.3 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea89118",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_clean[numeric_cols].corr().round(3)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_DIR / 'correlation_heatmap.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea45e54",
   "metadata": {},
   "source": [
    "### 7.4 Location-wise Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074e978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_summary = df_clean.groupby('location')[numeric_cols].agg(['mean','std','count'])\n",
    "loc_summary = loc_summary.round(2)\n",
    "loc_summary.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "# Show average Python marks by location\n",
    "avg_python = df_clean.groupby('location')['python_marks'].mean().sort_values(ascending=False)\n",
    "avg_python.plot(kind='bar')\n",
    "plt.ylabel('Average Python Marks')\n",
    "plt.title('Average Python Marks by Location')\n",
    "plt.tight_layout()\n",
    "plt.savefig(VIS_DIR / 'avg_python_by_location.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b1563",
   "metadata": {},
   "source": [
    "### 7.5 Statistical Tests\n",
    "\n",
    "We perform a few simple tests: ANOVA to check if mean Python marks differ across locations, and Pearson correlations for numeric pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f6f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA for python marks across locations\n",
    "locations = df_clean['location'].unique()\n",
    "groups = [df_clean[df_clean['location']==loc]['python_marks'].values for loc in locations]\n",
    "\n",
    "f_val, p_val = stats.f_oneway(*groups)\n",
    "print('ANOVA F-statistic:', round(f_val,3), 'p-value:', round(p_val,4))\n",
    "\n",
    "# Pearson correlation table (already computed in corr)\n",
    "from itertools import combinations\n",
    "pairs = list(combinations(numeric_cols, 2))\n",
    "pearson = {f'{a}__{b}': stats.pearsonr(df_clean[a], df_clean[b]) for a,b in pairs}\n",
    "# show a few\n",
    "{ k: (round(v[0],3), round(v[1],4)) for k,v in list(pearson.items())[:6] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb7e40",
   "metadata": {},
   "source": [
    "## 8. Results Narrative\n",
    "We summarize key findings from the EDA and statistical tests, highlighting significant patterns and insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae7c62",
   "metadata": {},
   "source": [
    "**Draft findings:**\n",
    "\n",
    "- The dataset contains 500 student records with no missing values after cleaning.\n",
    "- Mean marks across subjects are consistently in the mid-80s.\n",
    "- Correlation matrix shows weak relationships between subjects (no strong linear dependencies).\n",
    "- ANOVA on Python marks across locations produced a p-value > 0.05, indicating no statistically significant difference in means across cities (example; check actual output above)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568d124",
   "metadata": {},
   "source": [
    "## 9. Discussion\n",
    "\n",
    "The dataset shows consistently high student performance, with most subject averages in the mid-80s and no missing values. Correlations between subjects are weak, suggesting that strengths in one skill do not strongly predict performance in others. Age and location also show minimal influence, indicating evenly distributed abilities across the group. Overall, the dataset is clean, balanced, and ideal for demonstrating data cleaning, analysis, and visualization techniques without the variability or noise found in real-world data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26509e5f",
   "metadata": {},
   "source": [
    "## 10. Conclusion & Future Work\n",
    "\n",
    "\n",
    "- Add more demographic/contextual features (GPA, attendance, assignments).\n",
    "- Include temporal data for trend analysis.\n",
    "- Build predictive models to forecast student performance.\n",
    "- Expand agent capabilities to propose interventions based on insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5178cb9f",
   "metadata": {},
   "source": [
    "## 11. References\n",
    "\n",
    "- ProdigyFlow repository (this project)\n",
    "- Pandas documentation\n",
    "- Seaborn / Matplotlib docs\n",
    "- Scipy stats documentation\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Reproducibility & How to run\n",
    "\n",
    "1. Install dependencies in `requirements.txt`.\n",
    "2. Run cells in order or execute the pipeline via `python agents/main_agent.py`.\n",
    "3. Visual outputs are saved to `/visuals` and numeric summaries to `/reports`.\n",
    "\n",
    "**Files referenced in this notebook:**\n",
    "- `agents/cleaning_agent.py`, `agents/analysis_agent.py`, `agents/visualization_agent.py` (pipeline agents)\n",
    "- `data/data_science_student_marks.csv` (raw data)\n",
    "- `data/cleaned_student_data_academic.csv` (cleaned output)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
